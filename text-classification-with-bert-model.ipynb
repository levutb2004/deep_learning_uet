{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8962314,"sourceType":"datasetVersion","datasetId":5394482},{"sourceId":8962321,"sourceType":"datasetVersion","datasetId":5394454},{"sourceId":9026739,"sourceType":"datasetVersion","datasetId":5366160}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:54.349527Z","iopub.execute_input":"2024-12-14T14:03:54.350291Z","iopub.status.idle":"2024-12-14T14:03:54.366853Z","shell.execute_reply.started":"2024-12-14T14:03:54.350253Z","shell.execute_reply":"2024-12-14T14:03:54.365669Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/topic-dataset/train_markov.csv\n/kaggle/input/topic-dataset/train_cleaned.csv\n/kaggle/input/topic-dataset/test_cleaned.csv\n/kaggle/input/facebook-data/Train_data.txt\n/kaggle/input/facebook-data/Train_bigdata.txt\n/kaggle/input/vietnamstopword/vietnamese-stopwords.txt\n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"import re\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertModel, AdamW, get_scheduler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:54.368221Z","iopub.execute_input":"2024-12-14T14:03:54.368507Z","iopub.status.idle":"2024-12-14T14:03:54.374231Z","shell.execute_reply.started":"2024-12-14T14:03:54.368478Z","shell.execute_reply":"2024-12-14T14:03:54.373215Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"train_path = \"/kaggle/input/facebook-data/Train_bigdata.txt\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:54.375485Z","iopub.execute_input":"2024-12-14T14:03:54.375800Z","iopub.status.idle":"2024-12-14T14:03:54.385126Z","shell.execute_reply.started":"2024-12-14T14:03:54.375769Z","shell.execute_reply":"2024-12-14T14:03:54.384373Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"data = []\nwith open(train_path, 'r', encoding='utf-8-sig') as file:\n    for line in file:\n        data.append(line.strip())\n\n# T·∫°o DataFrame t·ª´ d·ªØ li·ªáu\ndf = pd.DataFrame(data, columns=['text'])\n\ndf['label'] = df['text'].apply(lambda x: x.split(' ')[0].replace('__label__', ''))\ndf['text'] = df['text'].apply(lambda x: ' '.join(x.split(' ')[1:]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:54.387442Z","iopub.execute_input":"2024-12-14T14:03:54.388004Z","iopub.status.idle":"2024-12-14T14:03:55.645070Z","shell.execute_reply.started":"2024-12-14T14:03:54.387959Z","shell.execute_reply":"2024-12-14T14:03:55.644263Z"}},"outputs":[],"execution_count":95},{"cell_type":"code","source":"stopwords_path = '/kaggle/input/vietnamstopword/vietnamese-stopwords.txt'\nwith open(stopwords_path, 'r', encoding='utf-8') as file:\n    vietnamese_stopwords = set(line.strip() for line in file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:55.646225Z","iopub.execute_input":"2024-12-14T14:03:55.646529Z","iopub.status.idle":"2024-12-14T14:03:55.654687Z","shell.execute_reply.started":"2024-12-14T14:03:55.646498Z","shell.execute_reply":"2024-12-14T14:03:55.653590Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"def preprocess_text(text, stopwords):\n    # Lo·∫°i b·ªè ƒë∆∞·ªùng link\n    text = re.sub(r'http\\S+', '', text)\n    # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát, emojis v√† s·ªë\n    text = re.sub(r'[^\\w\\s]|_', '', text)\n    text = re.sub(r'\\d+', '', text)\n    text = text.strip()\n    # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng\n    text = text.lower()\n\n    # T√°ch t·ª´ v√† lo·∫°i b·ªè stopwords\n    words = text.split()\n    words = [word for word in words if word not in stopwords]\n    return ' '.join(words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:55.655954Z","iopub.execute_input":"2024-12-14T14:03:55.656713Z","iopub.status.idle":"2024-12-14T14:03:55.665808Z","shell.execute_reply.started":"2024-12-14T14:03:55.656666Z","shell.execute_reply":"2024-12-14T14:03:55.664704Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"df['clean_text'] = df['text'].apply(lambda x: preprocess_text(x, vietnamese_stopwords))\ndf = df.drop_duplicates('text', keep='first').reset_index(drop=True)\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:55.667125Z","iopub.execute_input":"2024-12-14T14:03:55.667687Z","iopub.status.idle":"2024-12-14T14:03:58.459113Z","shell.execute_reply.started":"2024-12-14T14:03:55.667623Z","shell.execute_reply":"2024-12-14T14:03:58.458169Z"}},"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"                                                    text  \\\n0      Theo h√†nh tr√¨nh tour du l·ªãch M·ªπ - B·ªù ƒê√¥ng, du ...   \n1      m√¨nh c·∫ßn t√¨m 1 ph√≤ng cho kho·∫£ng 3 ng∆∞·ªùi  quanh...   \n2      Cho thu√™ nh√† ri√™ng dt 60m/s√†n.  C√≥ 4 ph√≤ng ng·ªß...   \n3      Cho thu√™ nh√† ·ªü t·∫ßng 4 kh√©p k√≠n, 4/295 Nguy·ªÖn K...   \n4      ‚ñ∫ Crumpler jackpack full photo ‚ñ∫ gi√° : 800.000...   \n...                                                  ...   \n15218  C√ì G√å TRONG H√ÄNH TR√åNH ƒê·∫æN NH·∫¨T NG·∫ÆM HOA T·ª¨ ƒê·∫∞...   \n15219  C√ÅC M√ìN KIM CHI NGON CHO M√ôA THU -------------...   \n15220  C·∫ßn cho thu√™ Chung c∆∞ Greenstar 234 Ph·∫°m VƒÉn ƒê...   \n15221  B·ªë tr√≠ th√¥ng minh gi√∫p nh√† ·ªëng S√†i G√≤n kh√¥ng c...   \n15222  Ch√∫c m·ª´ng sinh nh·∫≠t Ho√†ng Gia Media Group tr√≤n...   \n\n                           label  \\\n0                        Du_lich   \n1                        Nha_dat   \n2                        Nha_dat   \n3                        Nha_dat   \n4                        Mua_sam   \n...                          ...   \n15218                    Du_lich   \n15219           Do_an_va_do_uong   \n15220                    Nha_dat   \n15221                Nha_va_vuon   \n15222  Kinh_doanh_va_Cong_nghiep   \n\n                                              clean_text  \n0      h√†nh tr√¨nh tour du l·ªãch m·ªπ b·ªù ƒë√¥ng du l·ªØ h√†nh ...  \n1      ph√≤ng quanh khu v·ª±c h·ªì t√πng m·∫≠u ph√≤ng kh√©p k√≠n...  \n2      thu√™ dt ms√†n ph√≤ng ng·ªß p tho√°ng m√°t an ninh ng...  \n3      thu√™ t·∫ßng kh√©p k√≠n nguy·ªÖn kho√°i b·∫øp t·ªß l·∫°nh l√≤...  \n4      crumpler jackpack full photo gi√° vnƒë vnƒë ƒë·ª±ng ...  \n...                                                  ...  \n15218  h√†nh tr√¨nh nh·∫≠t ng·∫Øm hoa t·ª≠ ƒë·∫±ng nh·∫≠t h√†nh tr√¨...  \n15219  m√≥n kim chi ngon m√πa thu ·ª±c ·ª±c·ª±cth·∫≠t ch·∫£y mi·∫øn...  \n15220  thu√™ c∆∞ greenstar ph·∫°m vƒÉn ƒë·ªìng b·∫Øc li√™m h√† n·ªô...  \n15221  b·ªë tr√≠ th√¥ng minh gi√∫p ·ªëng s√†i g√≤n ch·ªó t·ªëi b·ªë ...  \n15222  ch√∫c m·ª´ng sinh nh·∫≠t ho√†ng gia media group tr√≤n...  \n\n[15223 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Theo h√†nh tr√¨nh tour du l·ªãch M·ªπ - B·ªù ƒê√¥ng, du ...</td>\n      <td>Du_lich</td>\n      <td>h√†nh tr√¨nh tour du l·ªãch m·ªπ b·ªù ƒë√¥ng du l·ªØ h√†nh ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>m√¨nh c·∫ßn t√¨m 1 ph√≤ng cho kho·∫£ng 3 ng∆∞·ªùi  quanh...</td>\n      <td>Nha_dat</td>\n      <td>ph√≤ng quanh khu v·ª±c h·ªì t√πng m·∫≠u ph√≤ng kh√©p k√≠n...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cho thu√™ nh√† ri√™ng dt 60m/s√†n.  C√≥ 4 ph√≤ng ng·ªß...</td>\n      <td>Nha_dat</td>\n      <td>thu√™ dt ms√†n ph√≤ng ng·ªß p tho√°ng m√°t an ninh ng...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Cho thu√™ nh√† ·ªü t·∫ßng 4 kh√©p k√≠n, 4/295 Nguy·ªÖn K...</td>\n      <td>Nha_dat</td>\n      <td>thu√™ t·∫ßng kh√©p k√≠n nguy·ªÖn kho√°i b·∫øp t·ªß l·∫°nh l√≤...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>‚ñ∫ Crumpler jackpack full photo ‚ñ∫ gi√° : 800.000...</td>\n      <td>Mua_sam</td>\n      <td>crumpler jackpack full photo gi√° vnƒë vnƒë ƒë·ª±ng ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15218</th>\n      <td>C√ì G√å TRONG H√ÄNH TR√åNH ƒê·∫æN NH·∫¨T NG·∫ÆM HOA T·ª¨ ƒê·∫∞...</td>\n      <td>Du_lich</td>\n      <td>h√†nh tr√¨nh nh·∫≠t ng·∫Øm hoa t·ª≠ ƒë·∫±ng nh·∫≠t h√†nh tr√¨...</td>\n    </tr>\n    <tr>\n      <th>15219</th>\n      <td>C√ÅC M√ìN KIM CHI NGON CHO M√ôA THU -------------...</td>\n      <td>Do_an_va_do_uong</td>\n      <td>m√≥n kim chi ngon m√πa thu ·ª±c ·ª±c·ª±cth·∫≠t ch·∫£y mi·∫øn...</td>\n    </tr>\n    <tr>\n      <th>15220</th>\n      <td>C·∫ßn cho thu√™ Chung c∆∞ Greenstar 234 Ph·∫°m VƒÉn ƒê...</td>\n      <td>Nha_dat</td>\n      <td>thu√™ c∆∞ greenstar ph·∫°m vƒÉn ƒë·ªìng b·∫Øc li√™m h√† n·ªô...</td>\n    </tr>\n    <tr>\n      <th>15221</th>\n      <td>B·ªë tr√≠ th√¥ng minh gi√∫p nh√† ·ªëng S√†i G√≤n kh√¥ng c...</td>\n      <td>Nha_va_vuon</td>\n      <td>b·ªë tr√≠ th√¥ng minh gi√∫p ·ªëng s√†i g√≤n ch·ªó t·ªëi b·ªë ...</td>\n    </tr>\n    <tr>\n      <th>15222</th>\n      <td>Ch√∫c m·ª´ng sinh nh·∫≠t Ho√†ng Gia Media Group tr√≤n...</td>\n      <td>Kinh_doanh_va_Cong_nghiep</td>\n      <td>ch√∫c m·ª´ng sinh nh·∫≠t ho√†ng gia media group tr√≤n...</td>\n    </tr>\n  </tbody>\n</table>\n<p>15223 rows √ó 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":98},{"cell_type":"code","source":"label_map = {label: i for i, label in enumerate(sorted(df['label'].unique()))}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:58.460696Z","iopub.execute_input":"2024-12-14T14:03:58.461455Z","iopub.status.idle":"2024-12-14T14:03:58.467968Z","shell.execute_reply.started":"2024-12-14T14:03:58.461408Z","shell.execute_reply":"2024-12-14T14:03:58.466923Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(\n    df['clean_text'], df['label'], test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:58.469300Z","iopub.execute_input":"2024-12-14T14:03:58.469700Z","iopub.status.idle":"2024-12-14T14:03:58.480679Z","shell.execute_reply.started":"2024-12-14T14:03:58.469655Z","shell.execute_reply":"2024-12-14T14:03:58.479588Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:58.483406Z","iopub.execute_input":"2024-12-14T14:03:58.483721Z","iopub.status.idle":"2024-12-14T14:03:58.697265Z","shell.execute_reply.started":"2024-12-14T14:03:58.483690Z","shell.execute_reply":"2024-12-14T14:03:58.696140Z"}},"outputs":[],"execution_count":101},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts.iloc[idx]\n        label = label_map[self.labels.iloc[idx]]\n\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_length,\n            return_tensors=\"pt\",\n        )\n\n        return {\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"label\": torch.tensor(label, dtype=torch.long),\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:58.698396Z","iopub.execute_input":"2024-12-14T14:03:58.698735Z","iopub.status.idle":"2024-12-14T14:03:58.706576Z","shell.execute_reply.started":"2024-12-14T14:03:58.698704Z","shell.execute_reply":"2024-12-14T14:03:58.705567Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"train_dataset = CustomDataset(X_train, y_train, tokenizer)\nval_dataset = CustomDataset(X_val, y_val, tokenizer)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:58.707838Z","iopub.execute_input":"2024-12-14T14:03:58.708198Z","iopub.status.idle":"2024-12-14T14:03:58.718723Z","shell.execute_reply.started":"2024-12-14T14:03:58.708155Z","shell.execute_reply":"2024-12-14T14:03:58.717931Z"}},"outputs":[],"execution_count":103},{"cell_type":"code","source":"class BERTClassifier(nn.Module):\n    def __init__(self, num_labels):\n        super(BERTClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.pooler_output\n        cls_output = self.dropout(cls_output)\n        logits = self.classifier(cls_output)\n        return logits\n\nnum_labels = len(label_map)\nmodel = BERTClassifier(num_labels)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:58.719950Z","iopub.execute_input":"2024-12-14T14:03:58.720233Z","iopub.status.idle":"2024-12-14T14:03:59.210928Z","shell.execute_reply.started":"2024-12-14T14:03:58.720200Z","shell.execute_reply":"2024-12-14T14:03:59.209973Z"}},"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"BERTClassifier(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (classifier): Linear(in_features=768, out_features=23, bias=True)\n)"},"metadata":{}}],"execution_count":104},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\nloss_fn = nn.CrossEntropyLoss()\nnum_training_steps = len(train_loader) * 3  # 3 epochs\nlr_scheduler = get_scheduler(\"linear\", optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:59.212084Z","iopub.execute_input":"2024-12-14T14:03:59.212410Z","iopub.status.idle":"2024-12-14T14:03:59.222028Z","shell.execute_reply.started":"2024-12-14T14:03:59.212380Z","shell.execute_reply":"2024-12-14T14:03:59.220919Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":105},{"cell_type":"code","source":"def train_epoch(model, train_loader, optimizer, loss_fn, scheduler):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n\n    for batch in train_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"label\"].to(device)\n\n        optimizer.zero_grad()\n        logits = model(input_ids, attention_mask)\n        loss = loss_fn(logits, labels)\n        total_loss += loss.item()\n\n        preds = torch.argmax(logits, dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n    avg_loss = total_loss / len(train_loader)\n    accuracy = correct / total\n    return avg_loss, accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:59.223457Z","iopub.execute_input":"2024-12-14T14:03:59.224059Z","iopub.status.idle":"2024-12-14T14:03:59.231872Z","shell.execute_reply.started":"2024-12-14T14:03:59.224010Z","shell.execute_reply":"2024-12-14T14:03:59.231008Z"}},"outputs":[],"execution_count":106},{"cell_type":"code","source":"def evaluate(model, val_loader, loss_fn):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            logits = model(input_ids, attention_mask)\n            loss = loss_fn(logits, labels)\n            total_loss += loss.item()\n\n            preds = torch.argmax(logits, dim=1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n    avg_loss = total_loss / len(val_loader)\n    accuracy = correct / total\n    return avg_loss, accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:59.233070Z","iopub.execute_input":"2024-12-14T14:03:59.233438Z","iopub.status.idle":"2024-12-14T14:03:59.241611Z","shell.execute_reply.started":"2024-12-14T14:03:59.233407Z","shell.execute_reply":"2024-12-14T14:03:59.240818Z"}},"outputs":[],"execution_count":107},{"cell_type":"code","source":"epochs = 20\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    train_loss, train_acc = train_epoch(model, train_loader, optimizer, loss_fn, lr_scheduler)\n    val_loss, val_acc = evaluate(model, val_loader, loss_fn)\n\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T14:03:59.242707Z","iopub.execute_input":"2024-12-14T14:03:59.242992Z","iopub.status.idle":"2024-12-14T15:54:12.909508Z","shell.execute_reply.started":"2024-12-14T14:03:59.242965Z","shell.execute_reply":"2024-12-14T15:54:12.908506Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\nTrain Loss: 1.5057, Train Accuracy: 0.5908, Val Loss: 0.7254, Val Accuracy: 0.8016\nEpoch 2/20\nTrain Loss: 0.6108, Train Accuracy: 0.8272, Val Loss: 0.5341, Val Accuracy: 0.8404\nEpoch 3/20\nTrain Loss: 0.4311, Train Accuracy: 0.8717, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 4/20\nTrain Loss: 0.3832, Train Accuracy: 0.8851, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 5/20\nTrain Loss: 0.3812, Train Accuracy: 0.8847, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 6/20\nTrain Loss: 0.3796, Train Accuracy: 0.8849, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 7/20\nTrain Loss: 0.3841, Train Accuracy: 0.8813, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 8/20\nTrain Loss: 0.3830, Train Accuracy: 0.8881, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 9/20\nTrain Loss: 0.3813, Train Accuracy: 0.8836, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 10/20\nTrain Loss: 0.3820, Train Accuracy: 0.8845, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 11/20\nTrain Loss: 0.3828, Train Accuracy: 0.8840, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 12/20\nTrain Loss: 0.3803, Train Accuracy: 0.8867, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 13/20\nTrain Loss: 0.3811, Train Accuracy: 0.8855, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 14/20\nTrain Loss: 0.3833, Train Accuracy: 0.8835, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 15/20\nTrain Loss: 0.3812, Train Accuracy: 0.8861, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 16/20\nTrain Loss: 0.3822, Train Accuracy: 0.8831, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 17/20\nTrain Loss: 0.3801, Train Accuracy: 0.8847, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 18/20\nTrain Loss: 0.3816, Train Accuracy: 0.8854, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 19/20\nTrain Loss: 0.3793, Train Accuracy: 0.8874, Val Loss: 0.4850, Val Accuracy: 0.8522\nEpoch 20/20\nTrain Loss: 0.3826, Train Accuracy: 0.8829, Val Loss: 0.4850, Val Accuracy: 0.8522\n","output_type":"stream"}],"execution_count":108},{"cell_type":"code","source":"model_save_path = \"bert_classifier_model.pth\"\ntorch.save(model.state_dict(), model_save_path)\nprint(f\"Model saved to {model_save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T16:30:38.511503Z","iopub.execute_input":"2024-12-14T16:30:38.512232Z","iopub.status.idle":"2024-12-14T16:30:39.217466Z","shell.execute_reply.started":"2024-12-14T16:30:38.512194Z","shell.execute_reply":"2024-12-14T16:30:39.216490Z"}},"outputs":[{"name":"stdout","text":"Model saved to bert_classifier_model.pth\n","output_type":"stream"}],"execution_count":127},{"cell_type":"code","source":"def predict(model, data_loader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            logits = model(input_ids, attention_mask)\n            preds = torch.argmax(logits, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    return all_preds, all_labels\n\nval_preds, val_labels = predict(model, val_loader)\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(val_labels, val_preds, target_names=label_map.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T15:54:12.910790Z","iopub.execute_input":"2024-12-14T15:54:12.911159Z","iopub.status.idle":"2024-12-14T15:54:42.810971Z","shell.execute_reply.started":"2024-12-14T15:54:12.911111Z","shell.execute_reply":"2024-12-14T15:54:42.810016Z"}},"outputs":[{"name":"stdout","text":"\nClassification Report:\n\n                              precision    recall  f1-score   support\n\n                   Chinh_tri       0.83      0.93      0.88       161\n         Con_nguoi_va_xa_hoi       0.71      0.86      0.78        78\n               Cong_nghe_moi       1.00      0.83      0.91         6\n            Do_an_va_do_uong       0.95      0.99      0.97       473\n                     Du_lich       0.88      0.91      0.89       191\n                    Giai_tri       0.94      0.98      0.96        48\n                    Giao_duc       0.86      0.95      0.90       138\n                  Giao_thong       0.81      1.00      0.89        25\n                    Khoa_hoc       0.86      0.17      0.28        36\n   Kinh_doanh_va_Cong_nghiep       0.63      0.80      0.71       388\n         Lam_dep_va_the_hinh       0.84      0.92      0.88        53\n Mang_internet_va_vien_thong       0.97      0.92      0.95       116\nMay_tinh_va_thiet_bi_dien_tu       0.95      0.88      0.91        42\n                     Mua_sam       0.91      0.87      0.89       248\n                  Nghe_thuat       0.96      0.95      0.96       126\n                     Nha_dat       0.96      0.98      0.97       496\n                 Nha_va_vuon       0.67      0.80      0.73        46\n                   Phap_luat       0.00      0.00      0.00        23\n                        Sach       0.91      0.95      0.93        76\n        Suc_khoe_va_benh_tat       0.68      0.47      0.56        32\n                   Tai_chinh       0.53      0.23      0.32       191\n                    The_thao       0.92      0.75      0.83        16\n       Thoi_quen_va_so_thich       1.00      0.50      0.67        36\n\n                    accuracy                           0.85      3045\n                   macro avg       0.82      0.77      0.77      3045\n                weighted avg       0.84      0.85      0.84      3045\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":109},{"cell_type":"code","source":"test_path = \"/kaggle/input/facebook-data/Train_data.txt\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T15:54:42.812156Z","iopub.execute_input":"2024-12-14T15:54:42.812446Z","iopub.status.idle":"2024-12-14T15:54:42.817367Z","shell.execute_reply.started":"2024-12-14T15:54:42.812416Z","shell.execute_reply":"2024-12-14T15:54:42.816348Z"}},"outputs":[],"execution_count":110},{"cell_type":"code","source":"test_data = []\nwith open(test_path, 'r', encoding='utf-8-sig') as file:\n    for line in file:\n        test_data.append(line.strip())\n\ntest_df = pd.DataFrame(test_data, columns=['text'])\n\n# T√°ch nh√£n v√† vƒÉn b·∫£n\ntest_df['label'] = test_df['text'].apply(lambda x: x.split(' ')[0].replace('__label__', ''))\ntest_df['text'] = test_df['text'].apply(lambda x: ' '.join(x.split(' ')[1:]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T16:19:44.757418Z","iopub.execute_input":"2024-12-14T16:19:44.757827Z","iopub.status.idle":"2024-12-14T16:19:45.538975Z","shell.execute_reply.started":"2024-12-14T16:19:44.757791Z","shell.execute_reply":"2024-12-14T16:19:45.538193Z"}},"outputs":[],"execution_count":122},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df['clean_text'] = test_df['text'].apply(lambda x: preprocess_text(x, vietnamese_stopwords))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T16:19:45.540456Z","iopub.execute_input":"2024-12-14T16:19:45.540764Z","iopub.status.idle":"2024-12-14T16:19:47.312440Z","shell.execute_reply.started":"2024-12-14T16:19:45.540736Z","shell.execute_reply":"2024-12-14T16:19:47.311695Z"}},"outputs":[],"execution_count":123},{"cell_type":"code","source":"test_dataset = CustomDataset(test_df['clean_text'], test_df['label'], tokenizer)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T16:19:47.313453Z","iopub.execute_input":"2024-12-14T16:19:47.313756Z","iopub.status.idle":"2024-12-14T16:19:47.320693Z","shell.execute_reply.started":"2024-12-14T16:19:47.313726Z","shell.execute_reply":"2024-12-14T16:19:47.319823Z"}},"outputs":[],"execution_count":124},{"cell_type":"code","source":"test_preds, test_labels = predict(model, test_loader)\n\n# === Hi·ªÉn th·ªã k·∫øt qu·∫£ ===\nprint(\"\\nClassification Report (Test Data):\\n\")\nprint(classification_report(test_labels, test_preds, target_names=label_map.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T16:19:47.322740Z","iopub.execute_input":"2024-12-14T16:19:47.323016Z","iopub.status.idle":"2024-12-14T16:21:27.700400Z","shell.execute_reply.started":"2024-12-14T16:19:47.322988Z","shell.execute_reply":"2024-12-14T16:21:27.699405Z"}},"outputs":[{"name":"stdout","text":"\nClassification Report (Test Data):\n\n                              precision    recall  f1-score   support\n\n                   Chinh_tri       0.83      0.94      0.88       472\n         Con_nguoi_va_xa_hoi       0.69      0.88      0.77       205\n               Cong_nghe_moi       1.00      0.35      0.52        20\n            Do_an_va_do_uong       0.96      0.98      0.97      1425\n                     Du_lich       0.85      0.90      0.87       606\n                    Giai_tri       0.96      0.99      0.97       114\n                    Giao_duc       0.85      0.94      0.89       460\n                  Giao_thong       0.80      0.94      0.86        50\n                    Khoa_hoc       0.75      0.16      0.27        92\n   Kinh_doanh_va_Cong_nghiep       0.57      0.83      0.67      1407\n         Lam_dep_va_the_hinh       0.91      0.89      0.90       181\n Mang_internet_va_vien_thong       0.96      0.95      0.95       401\nMay_tinh_va_thiet_bi_dien_tu       0.93      0.95      0.94       119\n                     Mua_sam       0.89      0.90      0.90       762\n                  Nghe_thuat       0.97      0.93      0.95       398\n                     Nha_dat       0.95      0.96      0.95      1624\n                 Nha_va_vuon       0.76      0.71      0.73       158\n                   Phap_luat       0.33      0.01      0.02        80\n                        Sach       0.91      0.92      0.91       249\n        Suc_khoe_va_benh_tat       0.65      0.34      0.45       114\n                   Tai_chinh       0.49      0.16      0.24       906\n                    The_thao       0.88      0.67      0.76        52\n       Thoi_quen_va_so_thich       1.00      0.40      0.57       122\n\n                    accuracy                           0.82     10017\n                   macro avg       0.82      0.73      0.74     10017\n                weighted avg       0.81      0.82      0.80     10017\n\n","output_type":"stream"}],"execution_count":125},{"cell_type":"code","source":"# T·∫°o DataFrame k·∫øt qu·∫£\ntest_df['predicted_label'] = [list(label_map.keys())[pred] for pred in test_preds]\nprint(test_df[['text', 'label', 'predicted_label']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T16:21:27.701915Z","iopub.execute_input":"2024-12-14T16:21:27.702893Z","iopub.status.idle":"2024-12-14T16:21:27.719055Z","shell.execute_reply.started":"2024-12-14T16:21:27.702838Z","shell.execute_reply":"2024-12-14T16:21:27.717929Z"}},"outputs":[{"name":"stdout","text":"                                                text  \\\n0  G·∫•p ; Hi·ªán b√™n em ƒëang c·∫ßn thu√™ 1 ph√≤ng c√≥ Di·ªá...   \n1  üåà CH√ÄO NOEL ƒê√ìN M∆ØA QU√Ä T·∫∂NG . üòç Nh√¢n d·ªãp Noel...   \n2  üì¢üì¢üì¢ KH·ªûI C√îNG X√ÇY D·ª∞NG 33 CƒÇN NH√Ä PH·ªê LI·ªÄN K·ªÄ ...   \n3  S√°ng ng√†y h√¥m nay, BTC r·∫•t vui khi nh·∫≠n ƒë∆∞·ª£c s...   \n4  C·∫ßn cho thu√™ cƒÉn h·ªô chung c∆∞ d∆∞·ªõi s√†i ƒë·ªìng ƒë·ªëi...   \n\n                         label              predicted_label  \n0                      Nha_dat                      Nha_dat  \n1  Mang_internet_va_vien_thong  Mang_internet_va_vien_thong  \n2    Kinh_doanh_va_Cong_nghiep                      Nha_dat  \n3                         Sach                         Sach  \n4                      Nha_dat                      Nha_dat  \n","output_type":"stream"}],"execution_count":126}]}