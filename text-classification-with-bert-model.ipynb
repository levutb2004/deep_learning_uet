{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8962314,"sourceType":"datasetVersion","datasetId":5394482},{"sourceId":8962321,"sourceType":"datasetVersion","datasetId":5394454},{"sourceId":9026739,"sourceType":"datasetVersion","datasetId":5366160}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:06.038614Z","iopub.execute_input":"2024-12-16T05:04:06.038928Z","iopub.status.idle":"2024-12-16T05:04:06.047965Z","shell.execute_reply.started":"2024-12-16T05:04:06.038904Z","shell.execute_reply":"2024-12-16T05:04:06.047116Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/facebook-data/Train_data.txt\n/kaggle/input/facebook-data/Train_bigdata.txt\n/kaggle/input/vietnamstopword/vietnamese-stopwords.txt\n/kaggle/input/topic-dataset/train_markov.csv\n/kaggle/input/topic-dataset/train_cleaned.csv\n/kaggle/input/topic-dataset/test_cleaned.csv\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import re\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertModel, AdamW, get_scheduler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:06.049695Z","iopub.execute_input":"2024-12-16T05:04:06.049964Z","iopub.status.idle":"2024-12-16T05:04:06.054844Z","shell.execute_reply.started":"2024-12-16T05:04:06.049940Z","shell.execute_reply":"2024-12-16T05:04:06.053973Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"train_path = \"/kaggle/input/facebook-data/Train_bigdata.txt\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:06.056203Z","iopub.execute_input":"2024-12-16T05:04:06.056530Z","iopub.status.idle":"2024-12-16T05:04:06.066456Z","shell.execute_reply.started":"2024-12-16T05:04:06.056506Z","shell.execute_reply":"2024-12-16T05:04:06.065695Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"data = []\nwith open(train_path, 'r', encoding='utf-8-sig') as file:\n    for line in file:\n        data.append(line.strip())\n\n# Tạo DataFrame từ dữ liệu\ndf = pd.DataFrame(data, columns=['text'])\n\ndf['label'] = df['text'].apply(lambda x: x.split(' ')[0].replace('__label__', ''))\ndf['text'] = df['text'].apply(lambda x: ' '.join(x.split(' ')[1:]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:06.067524Z","iopub.execute_input":"2024-12-16T05:04:06.068053Z","iopub.status.idle":"2024-12-16T05:04:07.185588Z","shell.execute_reply.started":"2024-12-16T05:04:06.068027Z","shell.execute_reply":"2024-12-16T05:04:07.184873Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"stopwords_path = '/kaggle/input/vietnamstopword/vietnamese-stopwords.txt'\nwith open(stopwords_path, 'r', encoding='utf-8') as file:\n    vietnamese_stopwords = set(line.strip() for line in file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:07.187370Z","iopub.execute_input":"2024-12-16T05:04:07.187640Z","iopub.status.idle":"2024-12-16T05:04:07.193189Z","shell.execute_reply.started":"2024-12-16T05:04:07.187615Z","shell.execute_reply":"2024-12-16T05:04:07.192195Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def preprocess_text(text, stopwords):\n    # Loại bỏ đường link\n    text = re.sub(r'http\\S+', '', text)\n    # Loại bỏ các ký tự đặc biệt, emojis và số\n    text = re.sub(r'[^\\w\\s]|_', '', text)\n    text = re.sub(r'\\d+', '', text)\n    text = text.strip()\n    # Chuyển về chữ thường\n    text = text.lower()\n\n    # Tách từ và loại bỏ stopwords\n    words = text.split()\n    words = [word for word in words if word not in stopwords]\n    return ' '.join(words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:07.194163Z","iopub.execute_input":"2024-12-16T05:04:07.194484Z","iopub.status.idle":"2024-12-16T05:04:07.200385Z","shell.execute_reply.started":"2024-12-16T05:04:07.194446Z","shell.execute_reply":"2024-12-16T05:04:07.199548Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"df['clean_text'] = df['text'].apply(lambda x: preprocess_text(x, vietnamese_stopwords))\ndf = df.drop_duplicates('text', keep='first').reset_index(drop=True)\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:07.201367Z","iopub.execute_input":"2024-12-16T05:04:07.201694Z","iopub.status.idle":"2024-12-16T05:04:09.682512Z","shell.execute_reply.started":"2024-12-16T05:04:07.201657Z","shell.execute_reply":"2024-12-16T05:04:09.681509Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                                    text  \\\n0      Theo hành trình tour du lịch Mỹ - Bờ Đông, du ...   \n1      mình cần tìm 1 phòng cho khoảng 3 người  quanh...   \n2      Cho thuê nhà riêng dt 60m/sàn.  Có 4 phòng ngủ...   \n3      Cho thuê nhà ở tầng 4 khép kín, 4/295 Nguyễn K...   \n4      ► Crumpler jackpack full photo ► giá : 800.000...   \n...                                                  ...   \n15218  CÓ GÌ TRONG HÀNH TRÌNH ĐẾN NHẬT NGẮM HOA TỬ ĐẰ...   \n15219  CÁC MÓN KIM CHI NGON CHO MÙA THU -------------...   \n15220  Cần cho thuê Chung cư Greenstar 234 Phạm Văn Đ...   \n15221  Bố trí thông minh giúp nhà ống Sài Gòn không c...   \n15222  Chúc mừng sinh nhật Hoàng Gia Media Group tròn...   \n\n                           label  \\\n0                        Du_lich   \n1                        Nha_dat   \n2                        Nha_dat   \n3                        Nha_dat   \n4                        Mua_sam   \n...                          ...   \n15218                    Du_lich   \n15219           Do_an_va_do_uong   \n15220                    Nha_dat   \n15221                Nha_va_vuon   \n15222  Kinh_doanh_va_Cong_nghiep   \n\n                                              clean_text  \n0      hành trình tour du lịch mỹ bờ đông du lữ hành ...  \n1      phòng quanh khu vực hồ tùng mậu phòng khép kín...  \n2      thuê dt msàn phòng ngủ p thoáng mát an ninh ng...  \n3      thuê tầng khép kín nguyễn khoái bếp tủ lạnh lò...  \n4      crumpler jackpack full photo giá vnđ vnđ đựng ...  \n...                                                  ...  \n15218  hành trình nhật ngắm hoa tử đằng nhật hành trì...  \n15219  món kim chi ngon mùa thu ực ựcựcthật chảy miến...  \n15220  thuê cư greenstar phạm văn đồng bắc liêm hà nộ...  \n15221  bố trí thông minh giúp ống sài gòn chỗ tối bố ...  \n15222  chúc mừng sinh nhật hoàng gia media group tròn...  \n\n[15223 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Theo hành trình tour du lịch Mỹ - Bờ Đông, du ...</td>\n      <td>Du_lich</td>\n      <td>hành trình tour du lịch mỹ bờ đông du lữ hành ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mình cần tìm 1 phòng cho khoảng 3 người  quanh...</td>\n      <td>Nha_dat</td>\n      <td>phòng quanh khu vực hồ tùng mậu phòng khép kín...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cho thuê nhà riêng dt 60m/sàn.  Có 4 phòng ngủ...</td>\n      <td>Nha_dat</td>\n      <td>thuê dt msàn phòng ngủ p thoáng mát an ninh ng...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Cho thuê nhà ở tầng 4 khép kín, 4/295 Nguyễn K...</td>\n      <td>Nha_dat</td>\n      <td>thuê tầng khép kín nguyễn khoái bếp tủ lạnh lò...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>► Crumpler jackpack full photo ► giá : 800.000...</td>\n      <td>Mua_sam</td>\n      <td>crumpler jackpack full photo giá vnđ vnđ đựng ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15218</th>\n      <td>CÓ GÌ TRONG HÀNH TRÌNH ĐẾN NHẬT NGẮM HOA TỬ ĐẰ...</td>\n      <td>Du_lich</td>\n      <td>hành trình nhật ngắm hoa tử đằng nhật hành trì...</td>\n    </tr>\n    <tr>\n      <th>15219</th>\n      <td>CÁC MÓN KIM CHI NGON CHO MÙA THU -------------...</td>\n      <td>Do_an_va_do_uong</td>\n      <td>món kim chi ngon mùa thu ực ựcựcthật chảy miến...</td>\n    </tr>\n    <tr>\n      <th>15220</th>\n      <td>Cần cho thuê Chung cư Greenstar 234 Phạm Văn Đ...</td>\n      <td>Nha_dat</td>\n      <td>thuê cư greenstar phạm văn đồng bắc liêm hà nộ...</td>\n    </tr>\n    <tr>\n      <th>15221</th>\n      <td>Bố trí thông minh giúp nhà ống Sài Gòn không c...</td>\n      <td>Nha_va_vuon</td>\n      <td>bố trí thông minh giúp ống sài gòn chỗ tối bố ...</td>\n    </tr>\n    <tr>\n      <th>15222</th>\n      <td>Chúc mừng sinh nhật Hoàng Gia Media Group tròn...</td>\n      <td>Kinh_doanh_va_Cong_nghiep</td>\n      <td>chúc mừng sinh nhật hoàng gia media group tròn...</td>\n    </tr>\n  </tbody>\n</table>\n<p>15223 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"label_map = {label: i for i, label in enumerate(sorted(df['label'].unique()))}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:09.683824Z","iopub.execute_input":"2024-12-16T05:04:09.684499Z","iopub.status.idle":"2024-12-16T05:04:09.689950Z","shell.execute_reply.started":"2024-12-16T05:04:09.684455Z","shell.execute_reply":"2024-12-16T05:04:09.689075Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(\n    df['clean_text'], df['label'], test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:09.691079Z","iopub.execute_input":"2024-12-16T05:04:09.691416Z","iopub.status.idle":"2024-12-16T05:04:09.702187Z","shell.execute_reply.started":"2024-12-16T05:04:09.691378Z","shell.execute_reply":"2024-12-16T05:04:09.701434Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:09.703357Z","iopub.execute_input":"2024-12-16T05:04:09.704083Z","iopub.status.idle":"2024-12-16T05:04:09.846327Z","shell.execute_reply.started":"2024-12-16T05:04:09.704055Z","shell.execute_reply":"2024-12-16T05:04:09.845655Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts.iloc[idx]\n        label = label_map[self.labels.iloc[idx]]\n\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_length,\n            return_tensors=\"pt\",\n        )\n\n        return {\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n            \"label\": torch.tensor(label, dtype=torch.long),\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:09.847324Z","iopub.execute_input":"2024-12-16T05:04:09.847572Z","iopub.status.idle":"2024-12-16T05:04:09.853358Z","shell.execute_reply.started":"2024-12-16T05:04:09.847548Z","shell.execute_reply":"2024-12-16T05:04:09.852522Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"train_dataset = CustomDataset(X_train, y_train, tokenizer)\nval_dataset = CustomDataset(X_val, y_val, tokenizer)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:09.854203Z","iopub.execute_input":"2024-12-16T05:04:09.854558Z","iopub.status.idle":"2024-12-16T05:04:09.869581Z","shell.execute_reply.started":"2024-12-16T05:04:09.854517Z","shell.execute_reply":"2024-12-16T05:04:09.868878Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"class BERTClassifier(nn.Module):\n    def __init__(self, num_labels):\n        super(BERTClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        cls_output = outputs.pooler_output\n        cls_output = self.dropout(cls_output)\n        logits = self.classifier(cls_output)\n        return logits\n\nnum_labels = len(label_map)\nmodel = BERTClassifier(num_labels)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:09.870513Z","iopub.execute_input":"2024-12-16T05:04:09.870822Z","iopub.status.idle":"2024-12-16T05:04:10.217724Z","shell.execute_reply.started":"2024-12-16T05:04:09.870784Z","shell.execute_reply":"2024-12-16T05:04:10.216892Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"BERTClassifier(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (classifier): Linear(in_features=768, out_features=23, bias=True)\n)"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\nloss_fn = nn.CrossEntropyLoss()\nnum_training_steps = len(train_loader) * 10 \nlr_scheduler = get_scheduler(\"linear\", optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:10.221929Z","iopub.execute_input":"2024-12-16T05:04:10.222174Z","iopub.status.idle":"2024-12-16T05:04:10.230125Z","shell.execute_reply.started":"2024-12-16T05:04:10.222150Z","shell.execute_reply":"2024-12-16T05:04:10.229205Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"def train_epoch(model, train_loader, optimizer, loss_fn, scheduler):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n\n    for batch in train_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"label\"].to(device)\n\n        optimizer.zero_grad()\n        logits = model(input_ids, attention_mask)\n        loss = loss_fn(logits, labels)\n        total_loss += loss.item()\n\n        preds = torch.argmax(logits, dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n    avg_loss = total_loss / len(train_loader)\n    accuracy = correct / total\n    return avg_loss, accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:10.231209Z","iopub.execute_input":"2024-12-16T05:04:10.231546Z","iopub.status.idle":"2024-12-16T05:04:10.239664Z","shell.execute_reply.started":"2024-12-16T05:04:10.231522Z","shell.execute_reply":"2024-12-16T05:04:10.239003Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"def evaluate(model, val_loader, loss_fn):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            logits = model(input_ids, attention_mask)\n            loss = loss_fn(logits, labels)\n            total_loss += loss.item()\n\n            preds = torch.argmax(logits, dim=1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n    avg_loss = total_loss / len(val_loader)\n    accuracy = correct / total\n    return avg_loss, accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:10.240813Z","iopub.execute_input":"2024-12-16T05:04:10.241089Z","iopub.status.idle":"2024-12-16T05:04:10.248667Z","shell.execute_reply.started":"2024-12-16T05:04:10.241064Z","shell.execute_reply":"2024-12-16T05:04:10.247858Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"epochs = 20\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    train_loss, train_acc = train_epoch(model, train_loader, optimizer, loss_fn, lr_scheduler)\n    val_loss, val_acc = evaluate(model, val_loader, loss_fn)\n\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:04:10.249712Z","iopub.execute_input":"2024-12-16T05:04:10.250343Z","iopub.status.idle":"2024-12-16T05:13:04.852816Z","shell.execute_reply.started":"2024-12-16T05:04:10.250306Z","shell.execute_reply":"2024-12-16T05:13:04.851657Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\nTrain Loss: 2.7160, Train Accuracy: 0.1568, Val Loss: 2.7050, Val Accuracy: 0.1553\nEpoch 2/20\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[35], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, loss_fn)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[33], line 15\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, optimizer, loss_fn, scheduler)\u001b[0m\n\u001b[1;32m     13\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask)\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, labels)\n\u001b[0;32m---> 15\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":35},{"cell_type":"code","source":"model_save_path = \"bert_classifier_model.h5\"\ntorch.save(model.state_dict(), model_save_path)\nprint(f\"Model saved to {model_save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:13:04.853630Z","iopub.status.idle":"2024-12-16T05:13:04.853913Z","shell.execute_reply.started":"2024-12-16T05:13:04.853776Z","shell.execute_reply":"2024-12-16T05:13:04.853790Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict(model, data_loader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            logits = model(input_ids, attention_mask)\n            preds = torch.argmax(logits, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    return all_preds, all_labels\n\nval_preds, val_labels = predict(model, val_loader)\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(val_labels, val_preds, target_names=label_map.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:13:04.854869Z","iopub.status.idle":"2024-12-16T05:13:04.855324Z","shell.execute_reply.started":"2024-12-16T05:13:04.855081Z","shell.execute_reply":"2024-12-16T05:13:04.855103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_path = \"/kaggle/input/facebook-data/Train_data.txt\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:13:04.856400Z","iopub.status.idle":"2024-12-16T05:13:04.856821Z","shell.execute_reply.started":"2024-12-16T05:13:04.856604Z","shell.execute_reply":"2024-12-16T05:13:04.856626Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = []\nwith open(test_path, 'r', encoding='utf-8-sig') as file:\n    for line in file:\n        test_data.append(line.strip())\n\ntest_df = pd.DataFrame(test_data, columns=['text'])\n\n# Tách nhãn và văn bản\ntest_df['label'] = test_df['text'].apply(lambda x: x.split(' ')[0].replace('__label__', ''))\ntest_df['text'] = test_df['text'].apply(lambda x: ' '.join(x.split(' ')[1:]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:13:04.857915Z","iopub.status.idle":"2024-12-16T05:13:04.858360Z","shell.execute_reply.started":"2024-12-16T05:13:04.858118Z","shell.execute_reply":"2024-12-16T05:13:04.858140Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df['clean_text'] = test_df['text'].apply(lambda x: preprocess_text(x, vietnamese_stopwords))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:13:04.859154Z","iopub.status.idle":"2024-12-16T05:13:04.859591Z","shell.execute_reply.started":"2024-12-16T05:13:04.859369Z","shell.execute_reply":"2024-12-16T05:13:04.859392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = CustomDataset(test_df['clean_text'], test_df['label'], tokenizer)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:13:04.860404Z","iopub.status.idle":"2024-12-16T05:13:04.860829Z","shell.execute_reply.started":"2024-12-16T05:13:04.860597Z","shell.execute_reply":"2024-12-16T05:13:04.860618Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loaded_model = BERTClassifier(num_labels)\nloaded_model.load_state_dict(torch.load(model_save_path))\nloaded_model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:13:04.861639Z","iopub.status.idle":"2024-12-16T05:13:04.862072Z","shell.execute_reply.started":"2024-12-16T05:13:04.861839Z","shell.execute_reply":"2024-12-16T05:13:04.861861Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loss, test_acc = evaluate(loaded_model, test_loader, loss_fn)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:13:04.862924Z","iopub.status.idle":"2024-12-16T05:13:04.863369Z","shell.execute_reply.started":"2024-12-16T05:13:04.863129Z","shell.execute_reply":"2024-12-16T05:13:04.863150Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_preds, test_labels = predict(model, test_loader)\n\n# === Hiển thị kết quả ===\nprint(\"\\nClassification Report (Test Data):\\n\")\nprint(classification_report(test_labels, test_preds, target_names=label_map.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:13:04.864360Z","iopub.status.idle":"2024-12-16T05:13:04.864776Z","shell.execute_reply.started":"2024-12-16T05:13:04.864558Z","shell.execute_reply":"2024-12-16T05:13:04.864580Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport seaborn as sns\nimport numpy as np\n\n# === Hàm vẽ ma trận nhầm lẫn ===\ndef plot_confusion_matrix(true_labels, pred_labels, label_map):\n    cm = confusion_matrix(true_labels, pred_labels)\n    cm_display = ConfusionMatrixDisplay(cm, display_labels=list(label_map.keys()))\n    \n    # Vẽ với seaborn\n    plt.figure(figsize=(15, 12))\n    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=label_map.keys(), yticklabels=label_map.keys())\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted Labels\")\n    plt.ylabel(\"True Labels\")\n    plt.show()\n\n# === Vẽ ma trận nhầm lẫn với tập validation ===\nprint(\"\\nConfusion Matrix for Validation Set:\")\nplot_confusion_matrix(val_labels, val_preds, label_map)\n\n# === Vẽ ma trận nhầm lẫn với tập test (nếu cần) ===\nprint(\"\\nConfusion Matrix for Test Set:\")\nplot_confusion_matrix(test_labels, test_preds, label_map)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:13:04.865587Z","iopub.status.idle":"2024-12-16T05:13:04.866015Z","shell.execute_reply.started":"2024-12-16T05:13:04.865791Z","shell.execute_reply":"2024-12-16T05:13:04.865813Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tạo DataFrame kết quả\ntest_df['predicted_label'] = [list(label_map.keys())[pred] for pred in test_preds]\nprint(test_df[['text', 'label', 'predicted_label']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T05:13:04.866854Z","iopub.status.idle":"2024-12-16T05:13:04.867166Z","shell.execute_reply.started":"2024-12-16T05:13:04.867010Z","shell.execute_reply":"2024-12-16T05:13:04.867026Z"}},"outputs":[],"execution_count":null}]}